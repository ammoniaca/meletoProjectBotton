{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "986feefd-398e-4fec-9535-aa5fb70d4775",
   "metadata": {},
   "source": [
    "## Training XGBoost Regression\n",
    "\n",
    "- **General Parameters**:\n",
    "\n",
    "    - **booster** = [*gbtree*, *gblinear*, *dart*]. The booster parameter in XGBoost is crucial for defining the type of model you will train. It has three settings:\n",
    "        - **gbtree**: uses tree-based models for each boosting iteration. Default and most common choice, works well across a wide range of datasets;\n",
    "        - **gblinear**: employs linear models. This is preferable for datasets where relationships between variables are well approximated linearly;\n",
    "        - **dart**: implements DART --*Dropouts meet Multiple Additive Regression Trees*--, which helps prevent overfitting by employing a dropout approach during training. https://xgboosting.com/configure-xgboost-booster-parameter/\n",
    "          \n",
    "    - **devise** = cpu\n",
    "\n",
    "    - **verbosity** = 2 (info)\n",
    "\n",
    "    - **nthread** = this is number of parallel threads used to run XGBoost.\n",
    "\n",
    "- **Parameters for Tree Booster**:\n",
    "\n",
    "    - **objective** = the objective parameter is the loss function to be minimized. For example, *\"reg:squarederror\"* for regression problem. https://xgboosting.com/configure-xgboost-objective-parameter/\n",
    "  \n",
    "    - **eval_metric** = the eval_metric parameter is the metric used for monitoring performance during training and for early stopping. For example *\"rmse\"* for root mean square error. It is important to choose the appropriate metric for the problem at hand. https://xgboosting.com/configure-xgboost-eval_metric-parameter/\n",
    "\n",
    "    - **early_stopping_rounds**: the early_stopping_rounds parameter specifies the number of rounds (iterations) to continue training after the last improvement in the model's performance on the validation set. Early stopping helps prevent overfitting by terminating training when the model’s performance on unseen data (validation set) stops improving. This technique also saves computational resources by avoiding unnecessary iterations. https://xgboosting.com/configure-xgboost-early_stopping_rounds-parameter/\n",
    "   \n",
    "    - **n_estimators** [default=100]= the n_estimators parameter controls the number of trees in the model. Increasing this value generally improves model performance, but can also lead to overfitting. A common value for this parameter is between 50 and 1000. https://xgboosting.com/configure-xgboost-n_estimators-parameter/\n",
    "\n",
    "    - **learning_rate (eta)** [default=0.3] = the learning rate controls the step size at which the optimizer makes updates to the weights. A smaller eta value results in slower but more accurate updates, while a larger eta value results in faster but less accurate updates. However, setting a too small eta value can lead to slow convergence and a too high value can lead to underfitting. Range of $[0, 1]$. https://xgboosting.com/configure-xgboost-learning_rate-parameter/\n",
    "\n",
    "    - **min_split_loss (gamma)** [default=0]= the min_split_loss parameter in XGBoost is an alias for the gamma parameter, which controls the minimum loss reduction required to make a split on a leaf node of the tree. By adjusting min_split_loss, you can influence the model’s complexity and its ability to generalize. Range of $[0, \\infty]$. https://xgboosting.com/configure-xgboost-gamma-parameter/\n",
    "\n",
    "    - **max_depth** [default=6] = the max_depth parameter controls the maximum depth of the trees in the model. A larger max_depth value results in more complex models, which can lead to overfitting. A smaller max_depth value results in simpler models, which can lead to underfitting. max_depth accepts positive integer values. Range of $[0, \\infty]$. **Note**: **exact** tree method requires non-zero value. https://xgboosting.com/configure-xgboost-max_depth-parameter/\n",
    "\n",
    "    - **min_child_weight** [default=1] = the min_child_weight parameter determines the minimum sum of instance weight (hessian) needed in a child node for a split to be made. It is a regularization parameter that can help control overfitting by preventing the creation of overly complex trees. Range of $[0, \\infty]$. https://xgboosting.com/configure-xgboost-min_child_weight-parameter/\n",
    "\n",
    "    - **max_delta_step** [default=0] = the max_delta_step parameter determines the maximum delta step allowed for each tree's weight estimation during the model's training process. It can help make the model more conservative and robust to outliers by limiting the weight updates. Range of $[0, \\infty]$ and typical values of $[1,10]$ might help control the update.. **Higher** max_delta_step values allow for larger weight updates, potentially making the model more sensitive to extreme weights and outliers. This can be beneficial if the model is underfitting or struggling to capture complex patterns in the data. **Lower** max_delta_step values limit the weight updates, making the model more conservative and robust to outliers. This can be useful if the model is overly sensitive to noisy data or outliers. https://xgboosting.com/configure-xgboost-max_delta_step-parameter/\n",
    "\n",
    "    - **subsample** [default=1] = The subsample parameter controls the fraction of observations used for each tree. A smaller subsample value results in smaller and less complex models, which can help prevent overfitting. A larger subsample value results in larger and more complex models, which can lead to overfitting. subsample accepts values between 0 and 1, with 1 meaning that all observations are used for each tree. It is common to set this value between 0.5 and 1. Range of $(0,1]$. https://xgboosting.com/configure-xgboost-subsample-parameter/\n",
    "\n",
    "    - **tree_method** = [*auto*, *exact*, *approx*, *hist*] the “tree_method” parameter in XGBoost specifies the algorithm used to construct the trees. It has several options, including:\n",
    "        - **auto**: XGBoost selects the most appropriate method based on the dataset;\n",
    "        - **exact**: utilizes an exact greedy algorithm. Best for small to medium datasets where precision is paramount. **Note**: use **\"exact\"** when your dataset is not extremely large and model accuracy is the critical factor;\n",
    "        - **approx**: employs a histogram-based approximation of the greedy algorithm. Ideal for larger datasets to balance performance and speed;\n",
    "        - **hist**: uses a faster histogram optimized algorithm, suitable for most datasets due to its effective balance of memory usage and speed.\n",
    "    https://xgboosting.com/configure-xgboost-tree_method-parameter/\n",
    "\n",
    "    - **sampling_method** = [*uniform*, *gradient_based*] the sampling_method parameter in XGBoost plays a critical role in how training data is sampled when building trees. Proper configuration of this parameter can lead to improvements in training speed and model accuracy, making it a vital aspect for fine-tuning your XGBoost models. **Note**: It can only be changed to *'gradient_based'* if tree_method is set to *'hist'* and device is set to *'cuda'*. https://xgboosting.com/configure-xgboost-sampling_method-parameter/\n",
    " \n",
    "        - **uniform**: this method samples instances randomly and equally, giving each instance the same probability of being selected. It is straightforward and can be effective for datasets where every sample is similarly important;\n",
    "        - **gradient_based**: this approach prioritizes instances based on the magnitude of their gradients, meaning instances with higher errors --and thus steeper gradients-- are more likely to be selected. This method is particularly useful for complex datasets with imbalanced classes or significant noise. **Note**: gradient-based sampling is only support by **GPU Hist**.\n",
    "        \n",
    "    - **colsample_bytree** [default=1] = the colsample_bytree parameter controls the fraction of features used for each tree. In other words, colsample_bytree defines what percentage of features (columns) will be used for building each tree. A smaller colsample_bytree value results in smaller and less complex models, which can help prevent overfitting. A larger colsample_bytree value results in larger and more complex models, which can lead to overfitting. colsample_bytree accepts values between 0 and 1, with 1 meaning that all features are available for each tree. It is common to set this value between 0.5 and 1. Range of $(0, 1]$. https://xgboosting.com/configure-xgboost-colsample_bytree-parameter/\n",
    " \n",
    "    - **colsample_bylevel** [default=1] = the colsample_bylevel parameter determines the fraction of features (columns) to be randomly sampled at each level (depth) of the tree during the model’s training process. It is a regularization technique that can help prevent overfitting by reducing the number of features each level of the tree can access, thus encouraging the model to rely on different subsets of features at different depths. Range of $(0, 1]$. https://xgboosting.com/configure-xgboost-colsample_bylevel-parameter/\n",
    "\n",
    "    - **colsample_bynode** [default=1] = the colsample_bynode parameter determines the fraction of features (columns) to be randomly sampled at each node of the tree during the model’s training process. It is a regularization technique that can help prevent overfitting by reducing the number of features each node of the tree can access, thus encouraging the model to rely on different subsets of features at different nodes. Range of $(0, 1]$. https://xgboosting.com/configure-xgboost-colsample_bynode-parameter/\n",
    "\n",
    "    - **lambda (reg_lambda)** [default=1] = the lambda parameter is the L2 regularization term on weights. Larger values means more conservative model, it helps to reduce overfitting by adding a penalty term to the loss function.  By adjusting lambda, you can influence the model’s complexity and its ability to generalize. It is common to start with a relatively small value, such as lambda = 1 and increase it until the performance on the validation set stops improving. Range of $[0, \\infty]$. https://xgboosting.com/configure-xgboost-lambda-parameter/\n",
    "\n",
    "    - **alpha (reg_alpha)** [default=0] = the alpha parameter is the L1 regularization term on weights. Larger values means more conservative model, it helps to reduce overfitting by adding a penalty term to the loss function. It is common to start with a relatively small value, such as alpha = 0 and increase it until the performance on the validation set stops improving. Range of $[0, \\infty]$. https://xgboosting.com/configure-xgboost-alpha-parameter/\n",
    "\n",
    "    - **grow_policy** = [*depthwise*, *lossguide*] the grow_policy parameter in XGBoost determines how the trees are grown during the training process. By setting this parameter, you can influence the structure of the resulting trees and potentially improve the model's performance. https://xgboosting.com/configure-xgboost-grow_policy-parameter/\n",
    "        - **depthwise**: this policy grows the trees depth-wise, meaning it prioritizes achieving the maximum depth specified by the max_depth parameter. This growth policy tends to create deeper, more complex trees;\n",
    "        - **lossguide**: the tree growth process continues until the loss reduction is below a certain threshold or other stopping criteria are met. This growth policy often results in shallower trees compared to “depthwise”. \n",
    "\n",
    "    - **importance_type** = [*gain*, *weight*, *cover*, *total_gain*, *total_cover*] the importance_type parameter in XGBoost determines the method used to calculate feature importance scores, which are crucial for interpreting the model's decisions. **Note**: Use **gain** or **total_gain** when you want to understand the contribution of features to the model's performance. Features with higher gain scores have a more significant impact on the model's predictions. Use **weight** or **cover** when you want to identify the most frequently used or broadly applicable features. Features with higher weight or cover scores are used more often in the model's decision-making process. https://xgboosting.com/configure-xgboost-importance_type-parameter/\n",
    " \n",
    "         - **gain** (default): calculates the average gain of splits that use the feature. Gain represents the improvement in the model's performance due to the split;\n",
    "         - **weight**: measures the number of times a feature is used to split the data across all trees. Features used more frequently are considered more important;\n",
    "         - **cover**: calculates the average coverage of splits that use the feature. Coverage represents the number of samples affected by the split;\n",
    "         - **total_gain**: calculates the total gain of splits that use the feature, considering the feature's contribution across all trees;\n",
    "         - **total_cover**: calculates the total coverage of splits that use the feature, considering the feature’s coverage across all trees.\n",
    "\n",
    "- **scale_pos_weight** [default=1] = when working with imbalanced datasets, where the number of instances in each class is significantly different, it's crucial to adjust the scale_pos_weight parameter in XGBoost to improve model performance. The scale_pos_weight parameter in XGBoost is designed to handle class imbalance in **binary classification problems**. However, it has **no effect** on the performance of the **XGBRegressor model**, which is used for regression tasks. This parameter controls the balance between positive and negative weights during training, allowing the model to give more importance to the minority class. \n",
    "           \n",
    "- **Additional parameters for Dart Booster** (*booster=dart*):\n",
    "\n",
    "    - **sample_type** [default= uniform] = [*uniform*, *weighted*] the sample_type parameter in XGBoost’s Dart Booster controls how dropped trees are selected during the model training process. There are two options for this parameter:\n",
    "        - **uniform** (default): dropped trees are selected uniformly at random. Each tree has an equal probability of being dropped;\n",
    "        - **weighted**: dropped trees are selected in proportion to their weights. Trees with higher weights are more likely to be dropped. https://xgboosting.com/configure-xgboost-dart-sample_type-parameter/\n",
    "    \n",
    "    - **normalize_type** [default= tree] = [*tree*, *forest*] this parameter determines the type of normalization algorithm used for the weights of dropped trees and newly added trees during the boosting process. When using the XGBoost Dart booster, it's recommended to experiment with both normalize_type options along with other hyperparameters to find the best configuration for your specific use case. Keep in mind that the choice of normalization algorithm can affect the model's convergence and the interpretability of the feature importances. XGBoost Dart supports two normalization algorithms:\n",
    "        - **tree**: new trees have the same weight as each of the dropped trees;\n",
    "        - **forest**: new trees have the same weight as the sum of the dropped trees (forest). https://xgboosting.com/configure-xgboost-dart-normalize_type-parameter/\n",
    "\n",
    "\n",
    "    - **rate_drop** [default=0.0] = this parameter controls the dropout rate, which is the fraction of trees that are randomly dropped at each boosting iteration. By introducing this randomness, the Dart booster helps to regularize the model and prevent overfitting. The rate_drop parameter takes values between 0.0 and 1.0, where 0.0 means no trees are dropped (equivalent to the gbtree booster), and 1.0 means all trees are dropped (which would result in no model being learned). Typical values for rate_drop range from 0.0 to 0.5. Range of $[0.0, 1.0]$. https://xgboosting.com/configure-xgboost-dart-rate_drop-parameter/\n",
    " \n",
    "    - **one_drop** [default=0] = [*True*, *False*] when *True*, it ensures that at least one tree is always dropped during the dropout process at each boosting iteration. Using one_drop can provide additional regularization to the model and help prevent overfitting. https://xgboosting.com/configure-xgboost-dart-one_drop-parameter/\n",
    " \n",
    "    - **skip_drop** [default=0] = this parameter controls the probability of skipping the dropout procedure during a boosting iteration. When a dropout is skipped, new trees are added in the same manner as the gbtree booster. Notably, a non-zero skip_drop value takes precedence over the rate_drop and one_drop parameters. Range of $[0.0, 1.0]$. The skip_drop parameter takes values between 0.0 and 1.0, where 0.0 means the dropout procedure is never skipped (default behavior), and 1.0 means the dropout procedure is always skipped, effectively disabling the Dart booster’s dropout mechanism. Typical values for skip_drop range from 0.0 to 0.5. https://xgboosting.com/configure-xgboost-dart-skip_drop-parameter/\n",
    "\n",
    "\n",
    "https://medium.com/analytics-vidhya/xgboost-colsample-by-hyperparameters-explained-6c0bac1bdc1  \n",
    "https://medium.com/@rithpansanga/the-main-parameters-in-xgboost-and-their-effects-on-model-performance-4f9833cac7c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab317fe-5205-482b-9552-9b3bce04b46d",
   "metadata": {},
   "source": [
    "### Most Important XGBoost Hyperparameters to Tune\n",
    "- **max_depth** [default=6], valid range of $[0, \\infty]$, typical range: $[3, 10]$, integer\n",
    "- **min_child_weight** [default=1], valid range of $[0.0, \\infty]$, integer\n",
    "- **subsample** [default=1], valid range of $(0.0,1.0]$, typical range: $[0.5,1]$, float\n",
    "- **colsample_bytree** [default=1], valid range of $(0.0,1.0]$, float\n",
    "- **learning_rate (eta)** [default=0.3], valid range of $[0.0,1.0]$, typical range: $[0.01, 0.2]$.\n",
    "### Additional Hyperparameters to Consider Tuning\n",
    "- **gamma (min_split_loss)** [default=0], valid range of $[0.0, \\infty]$, \n",
    "- **reg_alpha (alpha)** [default=0], valid range of $[0.0, \\infty]$, \n",
    "- **reg_lambda (lambda)** [default=0], valid range of $[0.0, \\infty]$,\n",
    "- **scale_pos_weight** [default=1], **note**: binary classification problems, **no effect on the performance of the XGBRegressor model**\n",
    "- **n_estimators**, [default=100], valid range of $[1, \\infty]$, typical range: $[50, 1000]$\n",
    "\n",
    "https://xgboosting.com/most-important-xgboost-hyperparameters-to-tune/  \n",
    "https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning  \n",
    "https://medium.com/data-science/how-to-speed-up-xgboost-model-training-fcf4dc5dbe5f\n",
    "https://randomrealizations.com/posts/xgboost-parameter-tuning-with-optuna/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f136a489-16f3-4aea-974e-14a08df9c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
    "from datetime import datetime\n",
    "import time\n",
    "import joblib\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "from scipy.stats import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494065a0-9a06-4aed-b3d7-ca777f0c903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all dataframe columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af48b4e-83d0-4630-991b-07366311a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse_precent(y_true, y_pred):\n",
    "    # RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    # RMSE% rispetto alla media\n",
    "    return (rmse / np.mean(y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69aa0d70-b722-4d90-84c1-f3d429997433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treatment</th>\n",
       "      <th>target</th>\n",
       "      <th>botton_score</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>range</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>non_zero_per_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UTC</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>16.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>15.0750</td>\n",
       "      <td>1.3769</td>\n",
       "      <td>15.45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UTC</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>17.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>14.7333</td>\n",
       "      <td>2.5502</td>\n",
       "      <td>14.70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UTC</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>15.6</td>\n",
       "      <td>12.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>14.2000</td>\n",
       "      <td>1.3342</td>\n",
       "      <td>14.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Treatment  target  botton_score   max   min  range     mean     std  median  \\\n",
       "0       UTC    0.75        0.0430  16.3  13.1    3.2  15.0750  1.3769   15.45   \n",
       "1       UTC    0.33        0.1130  17.3  12.2    5.1  14.7333  2.5502   14.70   \n",
       "2       UTC    0.25        0.0406  15.6  12.7    2.9  14.2000  1.3342   14.25   \n",
       "\n",
       "   non_zero_per_row  \n",
       "0                 4  \n",
       "1                 3  \n",
       "2                 4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"meleto_per_analisi.csv\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9da097c-f34b-4431-aed0-062210d52d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment                                      [UTC, Brevis, BA, ACC]\n",
      "target              [0.75, 0.33, 0.25, 0.5, 0.67, 1.0, 0.0, 0.4, 0...\n",
      "botton_score        [0.043, 0.113, 0.0406, 0.0986, 0.0447, 0.1202,...\n",
      "max                 [16.3, 17.3, 15.6, 16.4, 15.7, 15.8, 15.1, 13....\n",
      "min                 [13.1, 12.2, 12.7, 9.0, 11.9, 11.0, 9.5, 7.5, ...\n",
      "range               [3.2, 5.1, 2.9, 7.4, 3.8, 4.8, 7.8, 7.6, 4.9, ...\n",
      "mean                [15.075, 14.7333, 14.2, 13.5, 13.3667, 13.6333...\n",
      "std                 [1.3769, 2.5502, 1.3342, 3.3882, 2.0429, 2.433...\n",
      "median              [15.45, 14.7, 14.25, 14.3, 12.5, 14.1, 16.7, 9...\n",
      "non_zero_per_row                                [4, 3, 1, 5, 2, 6, 7]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.apply(lambda col: col.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ca366-4a24-4124-b201-7093e8002f6f",
   "metadata": {},
   "source": [
    "## Solamente i dati senza trattamento (i.e., solo UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a1882be-f6db-4b96-9760-c2ed19ea6d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treatment</th>\n",
       "      <th>target</th>\n",
       "      <th>botton_score</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>range</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>non_zero_per_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UTC</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>16.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>15.0750</td>\n",
       "      <td>1.3769</td>\n",
       "      <td>15.45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UTC</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>17.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>14.7333</td>\n",
       "      <td>2.5502</td>\n",
       "      <td>14.70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UTC</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>15.6</td>\n",
       "      <td>12.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>14.2000</td>\n",
       "      <td>1.3342</td>\n",
       "      <td>14.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Treatment  target  botton_score   max   min  range     mean     std  median  \\\n",
       "0       UTC    0.75        0.0430  16.3  13.1    3.2  15.0750  1.3769   15.45   \n",
       "1       UTC    0.33        0.1130  17.3  12.2    5.1  14.7333  2.5502   14.70   \n",
       "2       UTC    0.25        0.0406  15.6  12.7    2.9  14.2000  1.3342   14.25   \n",
       "\n",
       "   non_zero_per_row  \n",
       "0                 4  \n",
       "1                 3  \n",
       "2                 4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>botton_score</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>range</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>non_zero_per_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>16.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>15.0750</td>\n",
       "      <td>1.3769</td>\n",
       "      <td>15.45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>17.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>14.7333</td>\n",
       "      <td>2.5502</td>\n",
       "      <td>14.70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0406</td>\n",
       "      <td>15.6</td>\n",
       "      <td>12.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>14.2000</td>\n",
       "      <td>1.3342</td>\n",
       "      <td>14.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  botton_score   max   min  range     mean     std  median  \\\n",
       "0    0.75        0.0430  16.3  13.1    3.2  15.0750  1.3769   15.45   \n",
       "1    0.33        0.1130  17.3  12.2    5.1  14.7333  2.5502   14.70   \n",
       "2    0.25        0.0406  15.6  12.7    2.9  14.2000  1.3342   14.25   \n",
       "\n",
       "   non_zero_per_row  \n",
       "0                 4  \n",
       "1                 3  \n",
       "2                 4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_utc = df[df['Treatment'] == 'UTC'].copy()  # copia esplicita per sicurezza\n",
    "display(df_utc.head(3))\n",
    "# drop Treatment\n",
    "df_utc = df_utc.drop(columns=['Treatment'])  # evita inplace\n",
    "display(df_utc.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c22823f-553a-4e10-9b64-89e05c690a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>botton_score</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>range</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>non_zero_per_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0430</td>\n",
       "      <td>16.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>15.0750</td>\n",
       "      <td>1.3769</td>\n",
       "      <td>15.45</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1130</td>\n",
       "      <td>17.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>14.7333</td>\n",
       "      <td>2.5502</td>\n",
       "      <td>14.70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0406</td>\n",
       "      <td>15.6</td>\n",
       "      <td>12.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>14.2000</td>\n",
       "      <td>1.3342</td>\n",
       "      <td>14.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   botton_score   max   min  range     mean     std  median  non_zero_per_row\n",
       "0        0.0430  16.3  13.1    3.2  15.0750  1.3769   15.45                 4\n",
       "1        0.1130  17.3  12.2    5.1  14.7333  2.5502   14.70                 3\n",
       "2        0.0406  15.6  12.7    2.9  14.2000  1.3342   14.25                 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = df_utc['target'] \n",
    "X = df_utc.drop(['target'], axis=1)\n",
    "display(X.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83a00ced-bac1-41f6-b64e-417659940e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa0e0bf-5657-4570-8a1a-260b609edab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>range</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>non_zero_per_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>21.48</td>\n",
       "      <td>19.41</td>\n",
       "      <td>2.07</td>\n",
       "      <td>20.4275</td>\n",
       "      <td>1.0159</td>\n",
       "      <td>20.41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>11.76</td>\n",
       "      <td>7.73</td>\n",
       "      <td>4.03</td>\n",
       "      <td>10.6760</td>\n",
       "      <td>1.6779</td>\n",
       "      <td>11.30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>11.30</td>\n",
       "      <td>5.35</td>\n",
       "      <td>5.95</td>\n",
       "      <td>8.4483</td>\n",
       "      <td>2.1202</td>\n",
       "      <td>8.40</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        max    min  range     mean     std  median  non_zero_per_row\n",
       "5015  21.48  19.41   2.07  20.4275  1.0159   20.41                 4\n",
       "1898  11.76   7.73   4.03  10.6760  1.6779   11.30                 5\n",
       "2846  11.30   5.35   5.95   8.4483  2.1202    8.40                 6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>range</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "      <th>non_zero_per_row</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>12.13</td>\n",
       "      <td>6.37</td>\n",
       "      <td>5.76</td>\n",
       "      <td>8.1900</td>\n",
       "      <td>2.2634</td>\n",
       "      <td>7.62</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>20.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>18.2500</td>\n",
       "      <td>2.3629</td>\n",
       "      <td>19.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>19.51</td>\n",
       "      <td>14.89</td>\n",
       "      <td>4.62</td>\n",
       "      <td>16.4533</td>\n",
       "      <td>2.6474</td>\n",
       "      <td>14.96</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        max    min  range     mean     std  median  non_zero_per_row\n",
       "1813  12.13   6.37   5.76   8.1900  2.2634    7.62                 5\n",
       "4377  20.00  15.00   5.00  18.2500  2.3629   19.00                 4\n",
       "212   19.51  14.89   4.62  16.4533  2.6474   14.96                 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove botton score\n",
    "X_train = X_train.drop(['botton_score'], axis=1)\n",
    "\n",
    "# remove botton score\n",
    "botton_score_test = X_test['botton_score']\n",
    "X_test = X_test.drop(['botton_score'], axis=1)\n",
    "\n",
    "# display for check\n",
    "display(X_train.head(3))\n",
    "display(X_test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a09e2b38-8d62-4871-9ec9-f5faeced068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for botton score for all sample no treatment\n",
    "metrics_botton_score = {\n",
    "    'Model': 'Botton score',\n",
    "    'MAE': mean_absolute_error(y_test, botton_score_test), # Mean Absolute Error\n",
    "    'MSE': mean_squared_error(y_test, botton_score_test), # Mean Squared Error\n",
    "    'RMSE': root_mean_squared_error(y_test, botton_score_test), # Root Mean Squared Error\n",
    "    'RMSE_per': rmse_precent(y_test, botton_score_test), # Root Mean Squared Error %    \n",
    "    'R2': r2_score(y_test, botton_score_test), # R^2\n",
    "    'Median_AE': median_absolute_error(y_test, botton_score_test) # Median Absolute Error\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a36ad7-9576-45ed-9a6f-c8f605f3a40c",
   "metadata": {},
   "source": [
    "## XGB Regression for only UTC sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff5f81a-2d33-45e3-b9d5-ea0bbbf76c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution for xgboost\n",
    "param_dist = {\n",
    "    'n_estimators': randint(500, 1500), # integer\n",
    "    'max_depth': randint(3, 10), # integer\n",
    "    'min_child_weight': randint(1, 50), # integer\n",
    "    'subsample': uniform(loc=0.5, scale=0.5), # float loc=0.5 (inizio intervallo) e scale=0.5 (lunghezza intervallo), 0-5 + 0.5 = 1\n",
    "    'colsample_bytree': uniform(loc=0.5, scale=0.5), # float\n",
    "    'learning_rate': beta(a=2, b=1, loc=0.05, scale=0.15), # Valori tra 0.1 e 0.2 saranno più probabili di quelli vicino a 0.05.\n",
    "    'gamma': loguniform(1e-2, 10),  # più densità vicino a 0.01–1, meno verso 10\n",
    "    'alpha': loguniform(1e-3, 10),  # 0.001 – 10 la maggior parte delle volte i valori ottimali sono bassi (vicino a 0–1), ma conviene testare anche numeri più grandi.\n",
    "    'lambda': loguniform(1e-3, 10)  # da 0.001 a 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ffb7b28-6402-4d8c-8e2e-d7cf2d075015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(booster=\"gbtree\", n_jobs=-1)\n",
    "\n",
    "# Perform randomized search\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=1000,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1\n",
    "    # random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model \n",
    "xgb_search.fit(X_train, y_train.squeeze())\n",
    "\n",
    "# Miglior modello e predizioni\n",
    "best_model = xgb_search.best_estimator_ # BEST MODEL\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "metrics = {\n",
    "    'Model': 'XGBoost',\n",
    "    'MAE': mean_absolute_error(y_test, y_pred), # Mean Absolute Error\n",
    "    'MSE': mean_squared_error(y_test, y_pred), # Mean Squared Error\n",
    "    'RMSE': root_mean_squared_error(y_test, y_pred), # Root Mean Squared Error\n",
    "    'RMSE_per': rmse_precent(y_test, y_pred), # Root Mean Squared Error %    \n",
    "    'R2': r2_score(y_test, y_pred), # R^2\n",
    "    'Median_AE': median_absolute_error(y_test, y_pred) # Median Absolute Error\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74e0f6ce-1072-469d-9cba-bf2873de228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all\n",
    "timestamp = datetime.now().strftime(\"%Y%m%dT%H%M\") # Timestamp per i file\n",
    "    \n",
    "# (1) Save Best Model\n",
    "joblib.dump(best_model, f\"XGB_gbtree_UTC_best_model_{timestamp}.pkl\")\n",
    "    \n",
    "# (2) Save Metrics\n",
    "df_metrics = pd.DataFrame([metrics_botton_score, metrics])  # una riga con tutte le metriche\n",
    "df_metrics.to_csv(f\"XGB_gbtree_UTC_evaluation_metrics_{timestamp}.csv\", index=False)\n",
    "    \n",
    "# (3) Save best hyper-parameters\n",
    "best_params = xgb_search.best_params_ # get best hyper-parameters\n",
    "df_params = pd.DataFrame([best_params])  # una riga con tutti gli iperparametri\n",
    "df_params.to_csv(f\"XGB_gbtree_UTC_best_params_{timestamp}.csv\", index=False)\n",
    "    \n",
    "# (4) Save y_test e y_pred\n",
    "df_pred = pd.DataFrame({'y_test': y_test.squeeze(), 'y_pred': y_pred})\n",
    "df_pred.to_csv(f\"XGB_gbtree_UTC_predictions_{timestamp}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "124fd953-96e6-4c78-8e80-6aa47d070626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors Botton score only UTC sample:\n",
      " - MAE: 0.3515\n",
      " - MSE: 0.2008\n",
      " - RMSE: 0.4481\n",
      " - RMSE_per: 97.7852\n",
      " - R2: -0.9067\n",
      " - Median Absolute Error: 0.3089\n"
     ]
    }
   ],
   "source": [
    "print(\"Errors Botton score only UTC sample:\")\n",
    "print(f\" - MAE: {round(metrics_botton_score['MAE'], 4)}\")\n",
    "print(f\" - MSE: {round(metrics_botton_score['MSE'], 4)}\")\n",
    "print(f\" - RMSE: {round(metrics_botton_score['RMSE'], 4)}\")\n",
    "print(f\" - RMSE_per: {round(metrics_botton_score['RMSE_per'], 4)}\")\n",
    "print(f\" - R2: {round(metrics_botton_score['R2'], 4)}\")\n",
    "print(f\" - Median Absolute Error: {round(metrics_botton_score['Median_AE'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bbf576a-ab87-4930-9795-994c986dc794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors XGboost only UTC sample:\n",
      " - MAE: 0.2069\n",
      " - MSE: 0.0704\n",
      " - RMSE: 0.2653\n",
      " - RMSE_per: 57.9045\n",
      " - R2: 0.3314\n",
      " - Median Absolute Error: 0.1678\n"
     ]
    }
   ],
   "source": [
    "print(\"Errors XGboost only UTC sample:\")\n",
    "print(f\" - MAE: {round(metrics['MAE'], 4)}\")\n",
    "print(f\" - MSE: {round(metrics['MSE'], 4)}\")\n",
    "print(f\" - RMSE: {round(metrics['RMSE'], 4)}\")\n",
    "print(f\" - RMSE_per: {round(metrics['RMSE_per'], 4)}\")\n",
    "print(f\" - R2: {round(metrics['R2'], 4)}\")\n",
    "print(f\" - Median Absolute Error: {round(metrics['Median_AE'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fcd3fd2-bf1f-430f-baf7-1a48aae070be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature importance:\n",
      "             Feature  Importance\n",
      "5            median    3.413118\n",
      "4               std    0.747078\n",
      "1               min    0.618179\n",
      "6  non_zero_per_row    0.451790\n",
      "0               max    0.449454\n",
      "2             range    0.403163\n",
      "3              mean    0.333027\n"
     ]
    }
   ],
   "source": [
    "importance = best_model.get_booster().get_score(importance_type='gain')\n",
    "\n",
    "# converti in DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': list(importance.keys()),\n",
    "    'Importance': list(importance.values())\n",
    "})\n",
    "\n",
    "# ordina in ordine decrescente\n",
    "feat_importances = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature importance:\\n\", feat_importances)\n",
    "\n",
    "feat_importances.to_csv(f\"XGB_gbtree_UTC_FeatureImportance_{timestamp}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7923f22e-5250-444d-a2c6-270152165ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.barh(feat_importances[\"Feature\"], feat_importances[\"Importance\"], color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Feature Importance - Best XGB Model - only untreated samples\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.gca().invert_yaxis() \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d5acd-a0d0-4247-98b1-3a0a90537f16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
